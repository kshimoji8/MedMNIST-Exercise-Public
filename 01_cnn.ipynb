{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第1回：MedMNISTによる深層学習モデル入門\n",
        "\n",
        "## 学習目標\n",
        "\n",
        "- Google Colab の扱いを学ぶ\n",
        "- 医用画像データセット MedMNIST の扱いを学ぶ\n",
        "- 畳み込みニューラルネットワーク（CNN）の学習プロセスを理解する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## MedMNISTとは\n",
        "\n",
        "MedMNISTは、医用画像を28×28ピクセルに標準化した教育用データセットです。病理画像、皮膚画像、胸部X線など、10種類以上の医療画像が含まれています。\n",
        "\n",
        "手書き数字認識で有名な「MNIST」の医療版と考えてください。MNISTが数字の「0〜9」を分類するように、MedMNISTは医療画像を「正常・異常」や「疾患の種類」で分類します。\n",
        "\n",
        "## CNN（畳み込みニューラルネットワーク）とは\n",
        "\n",
        "CNNは、画像認識に特化したニューラルネットワークです。画像の局所的な特徴（エッジや模様）を自動的に学習し、分類に活用します。\n",
        "\n",
        "人間が絵を見るとき、まず線や色を認識し、次に形を把握し、最後に「これは猫だ」と判断します。CNNも同様に、単純な特徴から複雑な特徴へと段階的に認識を深めていきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 環境セットアップ\n!pip install medmnist -q\nimport sys, os\n!rm -rf /tmp/MedMNIST-Exercise\n!git clone https://github.com/kshimoji8/MedMNIST-Exercise-Public.git /tmp/MedMNIST-Exercise -q\nsys.path.insert(0, '/tmp/MedMNIST-Exercise')\nsys.modules.pop('exercise_logic', None)\nimport exercise_logic\nexercise_logic.initialize_environment()\nprint(\"✓ セットアップが完了しました。\")\n\n# --- 病理データのロード ---\n(x_train, y_train), (x_test, y_test), info = exercise_logic.load_and_preprocess('pathmnist')\nprint(f\"✓ データロード完了: 訓練データ {x_train.shape}, ラベル {y_train.shape}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## CNNモデルの構成要素\n",
        "\n",
        "- **畳み込み層（Conv2D）**: 画像からエッジや模様などの特徴を抽出します。虫眼鏡で画像の一部分を見ながら「ここに線がある」「ここに丸がある」と特徴を見つけていくイメージです。\n",
        "\n",
        "- **プーリング層（MaxPooling2D）**: 特徴マップのサイズを縮小し、重要な情報を残します。写真を縮小しても何が写っているかわかるように、細かい情報を捨てて本質的な特徴だけを残します。\n",
        "\n",
        "- **全結合層（Dense）**: 抽出された特徴を元に、最終的な分類を行います。「エッジがこう並んでいて、この模様があるから、これは病変だ」と総合判断する部分です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# シンプルなCNNモデルを構築\n",
        "model = exercise_logic.build_model(\n",
        "    input_shape=(28, 28, 3), \n",
        "    num_classes=len(info['label']), \n",
        "    model_type='simple'\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 学習プロセスの用語\n",
        "\n",
        "- **エポック（epochs）**: 全データを何回繰り返し学習するかを指定します。教科書を1回読むより3回読んだ方が覚えられるように、繰り返し学習することで精度が向上します。\n",
        "\n",
        "- **バッチサイズ（batch_size）**: 一度に処理するデータの数です。単語帳を1枚ずつめくるか、10枚まとめて覚えるかの違いです。大きいほど学習が安定しますが、メモリを多く使います。\n",
        "\n",
        "- **検証データ（validation_split）**: 学習中に性能を確認するために分けておくデータの割合です。模擬試験のようなもので、本番（テストデータ）の前に実力を確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=10, \n",
        "    validation_split=0.1, \n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 評価指標の見方\n",
        "\n",
        "- **学習曲線**: 損失（loss）が下がり、精度（accuracy）が上がれば学習が進んでいます。ただし、訓練データの精度だけ上がって検証データの精度が上がらない場合は「過学習」の兆候です。丸暗記で応用が利かない状態と同じです。\n",
        "\n",
        "- **混同行列**: 実際のラベルと予測ラベルの対応を表にしたものです。対角線上の数値が多いほど正確です。「猫を犬と間違えた回数」「犬を猫と間違えた回数」などが一目でわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 評価と分析\n",
        "exercise_logic.plot_history(history)\n",
        "exercise_logic.show_evaluation_reports(model, x_test, y_test, info['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## CNNの中を覗いてみよう：特徴マップの可視化\n",
        "\n",
        "CNNが画像をどのように「見ている」かを確認してみましょう。\n",
        "\n",
        "畳み込み層を通過した後の画像（**特徴マップ**）を可視化すると、CNNが抽出している特徴を直接観察できます。\n",
        "\n",
        "- 第1層では、エッジや色の境界など単純な特徴を検出\n",
        "- 層が深くなるにつれて、より複雑なパターンを認識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# テスト画像の特徴マップを可視化\n",
        "sample_image = x_test[0]\n",
        "\n",
        "# 第1畳み込み層の特徴マップを表示\n",
        "exercise_logic.visualize_feature_maps(model, sample_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNNの処理の流れ\n",
        "\n",
        "入力画像がどのように処理されて最終的な予測に至るか、一連の流れを確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CNNの処理の流れを可視化（入力→特徴抽出→予測）\n",
        "exercise_logic.visualize_cnn_flow(model, x_test[0], info['label'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 他の画像でも試してみよう\n",
        "\n",
        "`x_test[0]` の `0` を別の数字（例: `5`, `10`, `100`）に変えて、異なる画像での特徴マップを観察してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 別の画像で試す（数字を変えてみてください）\n",
        "exercise_logic.visualize_cnn_flow(model, x_test[5], info['label'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 練習問題\n",
        "\n",
        "### 練習1: エポック数を変更してみよう\n",
        "\n",
        "上の学習コードで `epochs=10` を `epochs=5` や `epochs=20` に変更して、精度がどう変わるか観察してください。\n",
        "\n",
        "```python\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=20,  # ← ここを変更\n",
        "    validation_split=0.1, \n",
        "    batch_size=128\n",
        ")\n",
        "```\n",
        "\n",
        "**観察ポイント:**\n",
        "- エポック数を増やすと精度は上がり続けますか？\n",
        "- 訓練精度と検証精度の差はどう変化しますか？\n",
        "\n",
        "### 練習2: バッチサイズを変更してみよう\n",
        "\n",
        "`batch_size=128` を `batch_size=32` や `batch_size=256` に変更して、学習の様子を比較してください。\n",
        "\n",
        "**観察ポイント:**\n",
        "- 学習速度（1エポックあたりの時間）はどう変わりますか？\n",
        "- 学習曲線の滑らかさに違いはありますか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 考察課題\n",
        "\n",
        "以下の点について考えてみましょう：\n",
        "\n",
        "1. **過学習の兆候**: 学習曲線で「訓練精度は上がり続けるのに、検証精度が下がり始める」現象が見られた場合、どう対処すべきでしょうか？\n",
        "\n",
        "2. **医療画像への応用**: 病理画像の分類にCNNを使う場合、「98%の精度」は十分でしょうか？残り2%の誤診が持つ意味について考えてください。\n",
        "\n",
        "3. **データの重要性**: 訓練データに偏りがある場合（例：特定の病院のデータのみ）、モデルの性能にどのような影響がありますか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## まとめ\n",
        "\n",
        "本講義で学んだ内容：\n",
        "\n",
        "- **MedMNIST**: 医用画像を28×28ピクセルに標準化した教育用データセット\n",
        "- **CNN**: 画像の特徴を自動的に学習し、分類を行うニューラルネットワーク\n",
        "- **畳み込み層**: 画像から局所的な特徴（エッジ、模様）を抽出\n",
        "- **プーリング層**: 特徴マップを縮小し、重要な情報を保持\n",
        "- **学習プロセス**: エポック数、バッチサイズ、検証データの役割\n",
        "- **評価指標**: 学習曲線と混同行列による性能評価\n",
        "\n",
        "次回は「転移学習」と「クラス不均衡への対処」を学びます。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
