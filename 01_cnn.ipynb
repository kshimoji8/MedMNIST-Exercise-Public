{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第1回：MedMNISTによる深層学習モデル入門\n",
        "\n",
        "## 学習目標\n",
        "\n",
        "- Google Colab の扱いを学ぶ\n",
        "- 医用画像データセット MedMNIST の扱いを学ぶ\n",
        "- 畳み込みニューラルネットワーク（CNN）の学習プロセスを理解する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ようこそ！医療AI開発の世界へ\n",
        "\n",
        "この講義では、**実際に動くコード**を通じて深層学習の基礎を学びます。\n",
        "プログラミングの経験がなくても大丈夫。セルを順番に実行していくだけで、\n",
        "あなた自身の手で「病理画像を診断するAI」を構築できます。\n",
        "\n",
        "## Google Colabとは\n",
        "\n",
        "Google Colaboratory（通称: Colab）は、ブラウザ上でPythonを実行できる無料の環境です。\n",
        "\n",
        "**Colabの特徴:**\n",
        "- インストール不要：ブラウザさえあれば、どのPCからでも利用可能\n",
        "- GPU無料利用：AIの学習に必要な高性能計算を無料で実行できる\n",
        "- 自動保存：作業内容はGoogleドライブに自動保存される\n",
        "\n",
        "**注意事項:**\n",
        "- 一定時間（約90分）操作しないとセッションが切断されます\n",
        "- 切断されても、上から順にセルを再実行すれば復旧できます\n",
        "- 講義中は定期的にセルを実行して、セッション切れを防ぎましょう\n",
        "\n",
        "## この講義の進め方\n",
        "\n",
        "1. **コードセルを上から順に実行**: `Shift + Enter` でセルを実行します\n",
        "2. **出力を観察**: 各セルの実行結果を確認しながら進めます\n",
        "3. **練習問題に挑戦**: パラメータを変更して、結果の変化を観察します\n",
        "4. **考察課題を考える**: 「なぜこうなるのか」を自分の言葉で説明してみましょう\n",
        "\n",
        "では、始めましょう！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## MedMNISTとは\n",
        "\n",
        "MedMNISTは、医用画像を28×28ピクセルに標準化した教育用データセットです。病理画像、皮膚画像、胸部X線など、10種類以上の医療画像が含まれています。\n",
        "\n",
        "手書き数字認識で有名な「MNIST」の医療版と考えてください。MNISTが数字の「0〜9」を分類するように、MedMNISTは医療画像を「正常・異常」や「疾患の種類」で分類します。\n",
        "\n",
        "## CNN（畳み込みニューラルネットワーク）とは\n",
        "\n",
        "CNNは、画像認識に特化したニューラルネットワークです。画像の局所的な特徴（エッジや模様）を自動的に学習し、分類に活用します。\n",
        "\n",
        "人間が絵を見るとき、まず線や色を認識し、次に形を把握し、最後に「これは猫だ」と判断します。CNNも同様に、単純な特徴から複雑な特徴へと段階的に認識を深めていきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# 環境セットアップ\n!pip install medmnist -q\nimport sys, os\n!rm -rf /tmp/MedMNIST-Exercise\n!git clone https://github.com/kshimoji8/MedMNIST-Exercise.git /tmp/MedMNIST-Exercise -q\nsys.path.insert(0, '/tmp/MedMNIST-Exercise')\nsys.modules.pop('exercise_logic', None)\nimport exercise_logic\nexercise_logic.initialize_environment()\nprint(\"✓ セットアップが完了しました。\")\n\n# --- 病理データのロード ---\n(x_train, y_train), (x_test, y_test), info = exercise_logic.load_and_preprocess('pathmnist')\nprint(f\"✓ データロード完了: 訓練データ {x_train.shape}, ラベル {y_train.shape}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## CNNモデルの構成要素\n",
        "\n",
        "- **畳み込み層（Conv2D）**: 画像からエッジや模様などの特徴を抽出します。虫眼鏡で画像の一部分を見ながら「ここに線がある」「ここに丸がある」と特徴を見つけていくイメージです。\n",
        "\n",
        "- **プーリング層（MaxPooling2D）**: 特徴マップのサイズを縮小し、重要な情報を残します。写真を縮小しても何が写っているかわかるように、細かい情報を捨てて本質的な特徴だけを残します。\n",
        "\n",
        "- **全結合層（Dense）**: 抽出された特徴を元に、最終的な分類を行います。「エッジがこう並んでいて、この模様があるから、これは病変だ」と総合判断する部分です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# シンプルなCNNモデルを構築\n",
        "model = exercise_logic.build_model(\n",
        "    input_shape=(28, 28, 3), \n",
        "    num_classes=len(info['label']), \n",
        "    model_type='simple'\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 学習プロセスの用語\n",
        "\n",
        "- **エポック（epochs）**: 全データを何回繰り返し学習するかを指定します。教科書を1回読むより3回読んだ方が覚えられるように、繰り返し学習することで精度が向上します。\n",
        "\n",
        "- **バッチサイズ（batch_size）**: 一度に処理するデータの数です。単語帳を1枚ずつめくるか、10枚まとめて覚えるかの違いです。大きいほど学習が安定しますが、メモリを多く使います。\n",
        "\n",
        "- **検証データ（validation_split）**: 学習中に性能を確認するために分けておくデータの割合です。模擬試験のようなもので、本番（テストデータ）の前に実力を確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=10, \n",
        "    validation_split=0.1, \n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 評価指標の見方\n",
        "\n",
        "- **学習曲線**: 損失（loss）が下がり、精度（accuracy）が上がれば学習が進んでいます。ただし、訓練データの精度だけ上がって検証データの精度が上がらない場合は「過学習」の兆候です。丸暗記で応用が利かない状態と同じです。\n",
        "\n",
        "- **混同行列**: 実際のラベルと予測ラベルの対応を表にしたものです。対角線上の数値が多いほど正確です。「猫を犬と間違えた回数」「犬を猫と間違えた回数」などが一目でわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 評価と分析\n",
        "exercise_logic.plot_history(history)\n",
        "exercise_logic.show_evaluation_reports(model, x_test, y_test, info['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## CNNの中を覗いてみよう：特徴マップの可視化\n",
        "\n",
        "CNNが画像をどのように「見ている」かを確認してみましょう。\n",
        "\n",
        "畳み込み層を通過した後の画像（**特徴マップ**）を可視化すると、CNNが抽出している特徴を直接観察できます。\n",
        "\n",
        "- 第1層では、エッジや色の境界など単純な特徴を検出\n",
        "- 層が深くなるにつれて、より複雑なパターンを認識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# テスト画像の特徴マップを可視化\n",
        "sample_image = x_test[0]\n",
        "\n",
        "# 第1畳み込み層の特徴マップを表示\n",
        "exercise_logic.visualize_feature_maps(model, sample_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNNの処理の流れ\n",
        "\n",
        "入力画像がどのように処理されて最終的な予測に至るか、一連の流れを確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CNNの処理の流れを可視化（入力→特徴抽出→予測）\n",
        "exercise_logic.visualize_cnn_flow(model, x_test[0], info['label'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 他の画像でも試してみよう\n",
        "\n",
        "`x_test[0]` の `0` を別の数字（例: `5`, `10`, `100`）に変えて、異なる画像での特徴マップを観察してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 別の画像で試す（数字を変えてみてください）\n",
        "exercise_logic.visualize_cnn_flow(model, x_test[5], info['label'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 練習問題\n",
        "\n",
        "### 練習1: エポック数を変更してみよう\n",
        "\n",
        "上の学習コードで `epochs=10` を `epochs=5` や `epochs=20` に変更して、精度がどう変わるか観察してください。\n",
        "\n",
        "```python\n",
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    epochs=20,  # ← ここを変更\n",
        "    validation_split=0.1, \n",
        "    batch_size=128\n",
        ")\n",
        "```\n",
        "\n",
        "**観察ポイント:**\n",
        "- エポック数を増やすと精度は上がり続けますか？\n",
        "- 訓練精度と検証精度の差はどう変化しますか？\n",
        "\n",
        "### 練習2: バッチサイズを変更してみよう\n",
        "\n",
        "`batch_size=128` を `batch_size=32` や `batch_size=256` に変更して、学習の様子を比較してください。\n",
        "\n",
        "**観察ポイント:**\n",
        "- 学習速度（1エポックあたりの時間）はどう変わりますか？\n",
        "- 学習曲線の滑らかさに違いはありますか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 考察課題\n",
        "\n",
        "以下の点について考えてみましょう：\n",
        "\n",
        "1. **過学習の兆候**: 学習曲線で「訓練精度は上がり続けるのに、検証精度が下がり始める」現象が見られた場合、どう対処すべきでしょうか？\n",
        "\n",
        "2. **医療画像への応用**: 病理画像の分類にCNNを使う場合、「98%の精度」は十分でしょうか？残り2%の誤診が持つ意味について考えてください。\n",
        "\n",
        "3. **データの重要性**: 訓練データに偏りがある場合（例：特定の病院のデータのみ）、モデルの性能にどのような影響がありますか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## まとめ\n",
        "\n",
        "本講義で学んだ内容：\n",
        "\n",
        "- **MedMNIST**: 医用画像を28×28ピクセルに標準化した教育用データセット\n",
        "- **CNN**: 画像の特徴を自動的に学習し、分類を行うニューラルネットワーク\n",
        "- **畳み込み層**: 画像から局所的な特徴（エッジ、模様）を抽出\n",
        "- **プーリング層**: 特徴マップを縮小し、重要な情報を保持\n",
        "- **学習プロセス**: エポック数、バッチサイズ、検証データの役割\n",
        "- **評価指標**: 学習曲線と混同行列による性能評価\n",
        "\n",
        "次回は「転移学習」と「クラス不均衡への対処」を学びます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 考察課題の回答例\n",
        "\n",
        "以下は考察課題に対する回答の一例です。これが唯一の正解ではなく、議論の出発点として活用してください。\n",
        "\n",
        "### 1. 過学習の兆候と対処法\n",
        "\n",
        "過学習（オーバーフィッティング）が疑われる場合の代表的な対処法：\n",
        "\n",
        "- **早期終了（Early Stopping）**: 検証損失（validation loss）や監視指標が一定期間改善しなくなったら（patienceを設けて）学習を停止する\n",
        "- **ドロップアウト**: 学習中にユニット（または結合）を確率的に無効化し、特定の特徴への過度な依存を抑える\n",
        "- **データ拡張**: 回転・反転・拡大縮小などで入力の多様性を増やし、汎化性能を高める（医療画像では不適切な拡張が診断所見を壊し得る点に注意）\n",
        "- **正則化**: 重み減衰（L2/weight decay）などでモデル複雑性にペナルティを与え、過度な当てはまりを抑制する\n",
        "\n",
        "### 2. 医療AIの「精度」の意味\n",
        "\n",
        "「正解率98%」は一見高いが、医療ではそれだけでは不十分なことがある：\n",
        "\n",
        "- 1000件の判定で誤りが2%なら、単純計算で20件の誤りが起こり得る\n",
        "- 医療では、正解率（accuracy）だけでなく、**感度・特異度、陽性的中率/陰性的中率（有病率に依存）、ROC/AUC**などの指標が重要になる\n",
        "- がんの見逃し（偽陰性）は治療開始の遅れにつながり得る一方、偽陽性は不要な検査・心理的負担・医療資源の消費につながり得る\n",
        "- 実運用では「意図された使用（診断支援、トリアージ等）」に応じて、重視すべき誤り（偽陰性/偽陽性）と閾値設計を明確にする\n",
        "\n",
        "### 3. データの偏り（バイアス）と汎化性能\n",
        "\n",
        "特定施設（単施設）のデータのみで学習すると：\n",
        "\n",
        "- 患者背景や紹介バイアス、撮影プロトコル、ラベル付けの流儀などに引きずられ、他施設で性能が落ちる可能性がある\n",
        "- 機器（メーカー、撮影条件、再構成条件）の差で分布が変わり、性能が変動し得る\n",
        "- **外部検証（別施設・別地域）**や、**時系列での検証（過去→現在）**を含めた評価が重要になる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 発展的な学習（技術的詳細に興味のある方へ）\n",
        "\n",
        "この講義では、技術的な詳細を `exercise_logic.py` に分離しています。\n",
        "より深く学びたい方は、以下の関数のソースコードを参照してください。\n",
        "\n",
        "### この講義で使用した主要関数\n",
        "\n",
        "| 関数名 | 機能 | 技術的なポイント |\n",
        "|--------|------|------------------|\n",
        "| `initialize_environment()` | 環境セットアップ | Colab/Local判定、GPU設定 |\n",
        "| `load_and_preprocess()` | データ読み込み・前処理 | MedMNISTの構造、正規化、チャンネル変換 |\n",
        "| `build_model()` | CNNモデル構築 | Conv2D、MaxPooling、活性化関数の役割 |\n",
        "| `plot_history()` | 学習曲線の描画 | 過学習の診断方法 |\n",
        "| `show_evaluation_reports()` | 評価指標の表示 | 混同行列、Precision/Recall/F1の意味 |\n",
        "| `visualize_feature_maps()` | 特徴マップ可視化 | Functional APIによる中間出力取得 |\n",
        "| `visualize_cnn_flow()` | CNN処理フロー可視化 | 入力から予測までの流れ |\n",
        "\n",
        "### ソースコードの参照方法\n",
        "\n",
        "`exercise_logic.py` はGitHubリポジトリで公開しています：\n",
        "\n",
        "https://github.com/kshimoji8/MedMNIST-Exercise/blob/main/exercise_logic.py\n",
        "\n",
        "各関数には詳細な技術解説をdocstring（関数冒頭のコメント）として記載しています。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
